{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import string\n",
    "\n",
    "# helper functions\n",
    "def contains(inputList, element):\n",
    "  '''uses binary search to find if a given list contains a certain element'''\n",
    "  low = 0\n",
    "  high = len(inputList)\n",
    "  while low < high:\n",
    "    mid = (low+high)//2\n",
    "    #print(low, high, mid)\n",
    "    if inputList[mid] == element:\n",
    "      return True\n",
    "    elif inputList[mid] < element:\n",
    "      low = mid + 1\n",
    "    else:\n",
    "      high = mid - 1\n",
    "  return False\n",
    "  \n",
    "  \n",
    "def get_words(fname):\n",
    "    '''returns list of processed [no whitespace/capitalization] lines of text from given file'''\n",
    "    f = open(fname)\n",
    "    lines_original = f.readlines()\n",
    "    lines_processed = []\n",
    "    for line in lines_original:\n",
    "        lines_processed.append(line.strip().lower())\n",
    "    f.close()\n",
    "    lines_processed.sort()\n",
    "    return lines_processed\n",
    "\n",
    "def process(message, remove_proper=True):\n",
    "    '''breaks message down into list of words without punctuation, whitespace, etc.'''\n",
    "    global informal_words\n",
    "    words_original = message.strip().split(\" \")\n",
    "    # remove punctuation and numbers (note to self: consider keeping in emojis)\n",
    "    words_processed_1 = []\n",
    "    for word in words_original:\n",
    "        new_word = word\n",
    "        for punc in string.punctuation:\n",
    "            new_word = new_word.replace(punc, \"\")\n",
    "        for num in string.digits:\n",
    "            new_word = new_word.replace(num, \"\")\n",
    "        if len(new_word) > 0:\n",
    "            words_processed_1.append(new_word)\n",
    "    # remove proper nouns\n",
    "    if remove_proper:\n",
    "        words_without_proper = []\n",
    "        for word in words_processed_1:\n",
    "            if not contains(english_words, word.lower()) and not contains(informal_words, word.lower()) and len(word)>1:\n",
    "                first_letter = word[0]\n",
    "                rest = word[1:]\n",
    "                if first_letter.isupper() and rest.islower():\n",
    "                    continue\n",
    "            words_without_proper.append(word)\n",
    "        words_processed_1 = words_without_proper\n",
    "    # make all words lowercase\n",
    "    words_processed_final = []\n",
    "    for word in words_processed_1:\n",
    "        if word != 'I':\n",
    "            words_processed_final.append(word.lower())\n",
    "        else: # exception since 'I' spelled as 'i' is a dead giveaway of many personal messages so keeping track of I capitalization can be useful\n",
    "            words_processed_final.append(word)\n",
    "    #print(words_processed_final)\n",
    "    return words_processed_final\n",
    "    \n",
    "# main function for classifying messages\n",
    "def calculate_index(message):\n",
    "    '''calculates 'formality index' of a given message'''\n",
    "    global english_words\n",
    "    global business_words \n",
    "    message_words = process(message)\n",
    "    # count misspelled words, emojis, abbreviations, etc.\n",
    "    informal_words_count = 0  \n",
    "    for word in message_words:\n",
    "        if word!='I' and (not contains(english_words, word) and not contains(informal_words, word)):\n",
    "            #print(word)\n",
    "            informal_words_count += 1\n",
    "    # count business words\n",
    "    business_words_count = 0\n",
    "    for word in message_words:\n",
    "        if word in business_words:\n",
    "            business_words_count += 1\n",
    "    # return index\n",
    "    num_words = len(message_words)\n",
    "    if num_words == 0:\n",
    "        return 0.5\n",
    "    #print(informal_words_count)\n",
    "    #print(business_words_count)\n",
    "    return ((num_words - informal_words_count)/num_words) * 0.75 + (business_words_count/num_words) * 0.25\n",
    "\n",
    "# uses index to return True (for business) or False (for personal)\n",
    "def is_business(message, cutoff=0.75):\n",
    "    '''classifies given message as business or personal'''\n",
    "    index = calculate_index(message)\n",
    "    if index>=cutoff:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# main code to check messages\n",
    "english_words = get_words(\"/Users/anisha/Downloads/sms-messages/dictionary_2.txt\")\n",
    "business_words = get_words(\"/Users/anisha/Downloads/sms-messages/business.txt\")\n",
    "informal_words = get_words(\"/Users/anisha/Downloads/sms-messages/informal.txt\")\n",
    "fpath = \"/Users/anisha/Downloads/sms-messages/personal-biz.csv\"\n",
    "true_positive = 0\n",
    "false_positive = 0\n",
    "true_negative = 0\n",
    "false_negative = 0\n",
    "lines_read = 0\n",
    "cutoff_num = 1000\n",
    "# go through set number of messages\n",
    "with open(fpath, newline='', encoding=\"latin1\") as messages_file:\n",
    "    lines = csv.DictReader(messages_file)\n",
    "    for line in lines:\n",
    "        lines_read += 1\n",
    "        answer = line['v1']\n",
    "        message = line['v2']\n",
    "        sender = is_business(message)\n",
    "        # update counters for true/false positive/negatives\n",
    "        if sender==True:\n",
    "            if answer==\"business\":\n",
    "                true_positive += 1\n",
    "            else:\n",
    "                false_positive += 1\n",
    "        else:\n",
    "            if answer==\"personal\":\n",
    "                true_negative += 1\n",
    "            else:\n",
    "                false_negative += 1\n",
    "        if lines_read==cutoff_num:\n",
    "            break\n",
    "# output results, calculate relevant measures\n",
    "accuracy = (true_positive + true_negative)/(true_positive + false_positive + true_negative + false_negative)\n",
    "precision = true_positive/(true_positive + false_positive)\n",
    "recall = true_positive/(true_positive + false_negative)\n",
    "print(\"{} true positives, {} false positives, {} true negatives, {} false negatives\".format(true_positive, false_positive, true_negative, false_negative))\n",
    "print(\"accuracy {}, precision {}, recall {}\".format(accuracy, precision, recall))\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 true positives, 7 false positives, 892 true negatives, 39 false negatives\n",
      "accuracy 0.954045954045954, precision 0.9, recall 0.6176470588235294\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import string\n",
    "\n",
    "def tokenize(message):\n",
    "    '''breaks message down into list of words without punctuation, whitespace, etc.'''\n",
    "    message = message.strip()\n",
    "    for num in string.digits:\n",
    "        message = message.replace(num, \"\")\n",
    "    for punc in string.punctuation:\n",
    "        if punc!=\"'\": # preserve contractions\n",
    "            message = message.replace(punc, \"\")\n",
    "    processed = message.split(\" \")\n",
    "    tokens = []\n",
    "    for token in processed:\n",
    "        if token!='':\n",
    "            tokens.append(token.lower())\n",
    "    return tokens\n",
    "\n",
    "\n",
    "# main function for classifying messages\n",
    "def calculate_index(message, matrix, availableTokens):\n",
    "    '''calculates 'formality index' of a given message'''\n",
    "    tokens = tokenize(message)\n",
    "    #print(tokens)\n",
    "    sum = 0\n",
    "    tokenCount = 0\n",
    "    for token in tokens:\n",
    "        if token in availableTokens:\n",
    "            sum += matrix[token][0]/(matrix[token][0] + matrix[token][1])\n",
    "            tokenCount += 1 \n",
    "    if tokenCount == 0:\n",
    "        return 0\n",
    "    return sum/tokenCount # average frequency of words\n",
    "\n",
    "# uses index to return True (for business) or False (for personal)\n",
    "def is_business(index, cutoff):\n",
    "    '''classifies given message as business or personal'''\n",
    "    if index>=cutoff:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# main code to check messages\n",
    "english_words = get_words(\"/Users/anisha/Downloads/sms-messages/dictionary_2.txt\")\n",
    "business_words = get_words(\"/Users/anisha/Downloads/sms-messages/business.txt\")\n",
    "informal_words = get_words(\"/Users/anisha/Downloads/sms-messages/informal.txt\")\n",
    "fpath = \"/Users/anisha/Downloads/sms-messages/personal-biz.csv\"\n",
    "true_positive = 0\n",
    "false_positive = 0\n",
    "true_negative = 0\n",
    "false_negative = 0\n",
    "lines_read = 0\n",
    "matrix = {}\n",
    "wordsSeen = set()\n",
    "cutoff_num = 5000\n",
    "# go through set number of messages\n",
    "with open(fpath, newline='', encoding=\"latin1\") as messages_file:\n",
    "    lines = csv.DictReader(messages_file)\n",
    "    for line in lines:\n",
    "        lines_read += 1\n",
    "        answer = line['v1']\n",
    "        message = line['v2']\n",
    "        if lines_read < 4000:\n",
    "            # frequency train on first 4000\n",
    "            tokens = tokenize(message)\n",
    "            if answer==\"business\":\n",
    "                use = 0\n",
    "            else:\n",
    "                use = 1\n",
    "            for token in tokens:\n",
    "                if token not in wordsSeen:\n",
    "                    wordsSeen.add(token)\n",
    "                    matrix[token] = [0, 0]\n",
    "                matrix[token][use] += 1\n",
    "        else:\n",
    "            # test on last 1000\n",
    "            score = calculate_index(message, matrix, wordsSeen)\n",
    "            sender = is_business(score, 0.5)\n",
    "            #print(message, score, answer)\n",
    "            # update counters for true/false positive/negatives\n",
    "            if sender==True:\n",
    "                if answer==\"business\":\n",
    "                    true_positive += 1\n",
    "                else:\n",
    "                    false_positive += 1\n",
    "            else:\n",
    "                if answer==\"personal\":\n",
    "                    true_negative += 1\n",
    "                else:\n",
    "                    false_negative += 1\n",
    "        if lines_read==cutoff_num:\n",
    "            break\n",
    "    # output results, calculate relevant measures\n",
    "    accuracy = (true_positive + true_negative)/(true_positive + false_positive + true_negative + false_negative)\n",
    "    precision = true_positive/(true_positive + false_positive)\n",
    "    recall = true_positive/(true_positive + false_negative)\n",
    "    print(\"{} true positives, {} false positives, {} true negatives, {} false negatives\".format(true_positive, false_positive, true_negative, false_negative))\n",
    "    print(\"accuracy {}, precision {}, recall {}\".format(accuracy, precision, recall))\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cutoff: 0.3\n",
      "133 true positives, 379 false positives, 814 true negatives, 0 false negatives\n",
      "accuracy 0.7141779788838613, precision 0.259765625, recall 1.0\n",
      "cutoff: 0.35\n",
      "133 true positives, 182 false positives, 1011 true negatives, 0 false negatives\n",
      "accuracy 0.8627450980392157, precision 0.4222222222222222, recall 1.0\n",
      "cutoff: 0.4\n",
      "131 true positives, 84 false positives, 1109 true negatives, 2 false negatives\n",
      "accuracy 0.9351432880844646, precision 0.6093023255813953, recall 0.9849624060150376\n",
      "cutoff: 0.45\n",
      "124 true positives, 27 false positives, 1166 true negatives, 9 false negatives\n",
      "accuracy 0.9728506787330317, precision 0.8211920529801324, recall 0.9323308270676691\n",
      "cutoff: 0.5\n",
      "85 true positives, 10 false positives, 1183 true negatives, 48 false negatives\n",
      "accuracy 0.9562594268476622, precision 0.8947368421052632, recall 0.6390977443609023\n",
      "cutoff: 0.55\n",
      "33 true positives, 4 false positives, 1189 true negatives, 100 false negatives\n",
      "accuracy 0.9215686274509803, precision 0.8918918918918919, recall 0.24812030075187969\n",
      "cutoff: 0.6\n",
      "11 true positives, 0 false positives, 1193 true negatives, 122 false negatives\n",
      "accuracy 0.9079939668174962, precision 1.0, recall 0.08270676691729323\n",
      "cutoff: 0.65\n",
      "5 true positives, 0 false positives, 1193 true negatives, 128 false negatives\n",
      "accuracy 0.9034690799396682, precision 1.0, recall 0.03759398496240601\n",
      "cutoff: 0.7\n",
      "1 true positives, 0 false positives, 1193 true negatives, 132 false negatives\n",
      "accuracy 0.9004524886877828, precision 1.0, recall 0.007518796992481203\n",
      "cutoff: 0.75\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kx/sb6s99kx507_h0pg94clvtwm0000gq/T/ipykernel_21539/4027097912.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cutoff: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0mprocess_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/kx/sb6s99kx507_h0pg94clvtwm0000gq/T/ipykernel_21539/4027097912.py\u001b[0m in \u001b[0;36mprocess_messages\u001b[0;34m(cutoff)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;31m# output results, calculate relevant measures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrue_positive\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrue_negative\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_positive\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfalse_positive\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrue_negative\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfalse_negative\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_positive\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_positive\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfalse_positive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_positive\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_positive\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfalse_negative\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} true positives, {} false positives, {} true negatives, {} false negatives\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_positive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_positive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_negative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_negative\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import string\n",
    "\n",
    "def tokenize(message):\n",
    "    '''breaks message down into list of words without punctuation, whitespace, etc.'''\n",
    "    message = message.strip()\n",
    "    for num in string.digits:\n",
    "        message = message.replace(num, \"\")\n",
    "    for punc in string.punctuation:\n",
    "        if punc!=\"'\": # preserve contractions\n",
    "            message = message.replace(punc, \"\")\n",
    "    processed = message.split(\" \")\n",
    "    tokens = []\n",
    "    for token in processed:\n",
    "        if token!='':\n",
    "            tokens.append(token.lower())\n",
    "    return tokens\n",
    "\n",
    "\n",
    "# main function for classifying messages\n",
    "def calculate_index(message, matrix, availableTokens):\n",
    "    '''calculates 'formality index' of a given message'''\n",
    "    tokens = tokenize(message)\n",
    "    #print(tokens)\n",
    "    sum = 0\n",
    "    tokenCount = 0\n",
    "    for token in tokens:\n",
    "        if token in availableTokens:\n",
    "            sum += matrix[token][0]/(matrix[token][0] + matrix[token][1])\n",
    "            tokenCount += 1 \n",
    "    if tokenCount == 0:\n",
    "        return 0\n",
    "    return sum/tokenCount # average frequency of words\n",
    "\n",
    "# uses index to return True (for business) or False (for personal)\n",
    "def is_business(index, cutoff):\n",
    "    '''classifies given message as business or personal'''\n",
    "    if index>=cutoff:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def process_messages(cutoff):\n",
    "    true_positive = 0\n",
    "    false_positive = 0\n",
    "    true_negative = 0\n",
    "    false_negative = 0\n",
    "    lines_read = 0\n",
    "    matrix = {}\n",
    "    wordsSeen = set()\n",
    "    fpath = \"/Users/anisha/Downloads/sms-messages/personal-biz.csv\"\n",
    "    with open(fpath, newline='', encoding=\"latin1\") as messages_file:\n",
    "        lines = csv.DictReader(messages_file)\n",
    "        for line in lines:\n",
    "            lines_read += 1\n",
    "            answer = line['v1']\n",
    "            message = line['v2']\n",
    "            if lines_read < 4000:\n",
    "                tokens = tokenize(message)\n",
    "                if answer==\"business\":\n",
    "                    use = 0\n",
    "                else:\n",
    "                    use = 1\n",
    "                for token in tokens:\n",
    "                    if token not in wordsSeen:\n",
    "                        wordsSeen.add(token)\n",
    "                        matrix[token] = [0, 0]\n",
    "                    matrix[token][use] += 1\n",
    "            else:\n",
    "                sender = is_business(calculate_index(message, matrix, wordsSeen), cutoff)\n",
    "                # update counters for true/false positive/negatives\n",
    "                if sender==True:\n",
    "                    if answer==\"business\":\n",
    "                        true_positive += 1\n",
    "                    else:\n",
    "                        false_positive += 1\n",
    "                else:\n",
    "                    if answer==\"personal\":\n",
    "                        true_negative += 1\n",
    "                    else:\n",
    "                        false_negative += 1\n",
    "    # output results, calculate relevant measures\n",
    "    accuracy = (true_positive + true_negative)/(true_positive + false_positive + true_negative + false_negative)\n",
    "    precision = true_positive/(true_positive + false_positive)\n",
    "    recall = true_positive/(true_positive + false_negative)\n",
    "    print(\"{} true positives, {} false positives, {} true negatives, {} false negatives\".format(true_positive, false_positive, true_negative, false_negative))\n",
    "    print(\"accuracy {}, precision {}, recall {}\".format(accuracy, precision, recall))\n",
    "\n",
    "\n",
    "# try different cutoff scores\n",
    "for i in range(30, 70, 5):\n",
    "    print(\"cutoff: \" + str(i/100))\n",
    "    process_messages(i/100)\n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 true positives, 12 false positives, 887 true negatives, 44 false negatives\n",
      "accuracy 0.9440559440559441, precision 0.8285714285714286, recall 0.5686274509803921\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes algorithm\n",
    "\n",
    "import csv\n",
    "import string\n",
    "\n",
    "def tokenize(message):\n",
    "    '''breaks message down into list of words without punctuation, whitespace, etc.'''\n",
    "    message = message.strip()\n",
    "    for num in string.digits:\n",
    "        message = message.replace(num, \"\")\n",
    "    for punc in string.punctuation:\n",
    "        if punc!=\"'\": # preserve contractions\n",
    "            message = message.replace(punc, \"\")\n",
    "    processed = message.split(\" \")\n",
    "    tokens = []\n",
    "    for token in processed:\n",
    "        if token!='':\n",
    "            tokens.append(token.lower())\n",
    "    return tokens\n",
    "\n",
    "\n",
    "# main function for classifying messages\n",
    "def calculate_probability(message, isBusiness):\n",
    "    '''calculates probability all words of a given message are business/personal'''\n",
    "    global matrix\n",
    "    global allTokens \n",
    "    global businessTokens \n",
    "    global personalTokens\n",
    "    tokens = tokenize(message)\n",
    "    #print(tokens)\n",
    "    prob = 1\n",
    "    tokenCount = 0\n",
    "    if isBusiness:\n",
    "        categoryID = 0\n",
    "        category = businessTokens\n",
    "    else:\n",
    "        categoryID = 1\n",
    "        category = personalTokens\n",
    "    for token in tokens:\n",
    "        if token in category:\n",
    "            category_appearances = matrix[token][categoryID]\n",
    "        else:\n",
    "            category_appearances = 0\n",
    "        prob *= (category_appearances + 1)/(len(category) + len(allTokens))\n",
    "    return prob # average frequency of words\n",
    "\n",
    "# uses index to return True (for business) or False (for personal)\n",
    "def is_business(message):\n",
    "    '''classifies given message as business or personal'''\n",
    "    bus_prob = calculate_probability(message, True)\n",
    "    pers_prob = calculate_probability(message, False)\n",
    "    return bus_prob > pers_prob\n",
    "\n",
    "# main code to check messages\n",
    "fpath = \"/Users/anisha/Downloads/sms-messages/personal-biz.csv\"\n",
    "true_positive = 0\n",
    "false_positive = 0\n",
    "true_negative = 0\n",
    "false_negative = 0\n",
    "lines_read = 0\n",
    "matrix = {}\n",
    "allTokens = set()\n",
    "businessTokens = set()\n",
    "personalTokens = set()\n",
    "cutoff_num = 5000\n",
    "# go through set number of messages\n",
    "with open(fpath, newline='', encoding=\"latin1\") as messages_file:\n",
    "    lines = csv.DictReader(messages_file)\n",
    "    for line in lines:\n",
    "        lines_read += 1\n",
    "        answer = line['v1']\n",
    "        message = line['v2']\n",
    "        if lines_read < 4000:\n",
    "            # frequency train on first 4000\n",
    "            tokens = tokenize(message)\n",
    "            if answer==\"business\":\n",
    "                use = 0\n",
    "            else:\n",
    "                use = 1\n",
    "            for token in tokens:\n",
    "                if token not in allTokens:\n",
    "                    allTokens.add(token)\n",
    "                    matrix[token] = [0, 0]\n",
    "                matrix[token][use] += 1\n",
    "                if use==0 and token not in businessTokens:\n",
    "                    businessTokens.add(token)\n",
    "                elif use==1 and token not in personalTokens:\n",
    "                    personalTokens.add(token)\n",
    "        else:\n",
    "            # test on last 1000\n",
    "            sender = is_business(message)\n",
    "            #print(message, sender, answer)\n",
    "            # update counters for true/false positive/negatives\n",
    "            if sender==True:\n",
    "                if answer==\"business\":\n",
    "                    true_positive += 1\n",
    "                else:\n",
    "                    false_positive += 1\n",
    "            else:\n",
    "                if answer==\"personal\":\n",
    "                    true_negative += 1\n",
    "                else:\n",
    "                    false_negative += 1\n",
    "        if lines_read==cutoff_num:\n",
    "            break\n",
    "    # output results, calculate relevant measures\n",
    "    accuracy = (true_positive + true_negative)/(true_positive + false_positive + true_negative + false_negative)\n",
    "    precision = true_positive/(true_positive + false_positive)\n",
    "    recall = true_positive/(true_positive + false_negative)\n",
    "    print(\"{} true positives, {} false positives, {} true negatives, {} false negatives\".format(true_positive, false_positive, true_negative, false_negative))\n",
    "    print(\"accuracy {}, precision {}, recall {}\".format(accuracy, precision, recall))\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 true positives, 27 false positives, 872 true negatives, 20 false negatives\n",
      "accuracy 0.9530469530469531, precision 0.7522935779816514, recall 0.803921568627451\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes algorithm with stopwords removed\n",
    "\n",
    "import csv\n",
    "import string\n",
    "\n",
    "# helper functions\n",
    "def contains(inputList, element):\n",
    "  '''uses binary search to find if a given list contains a certain element'''\n",
    "  low = 0\n",
    "  high = len(inputList)\n",
    "  while low < high:\n",
    "    mid = (low+high)//2\n",
    "    #print(low, high, mid)\n",
    "    #print(inputList[mid])\n",
    "    if inputList[mid] == element:\n",
    "      return True\n",
    "    elif inputList[mid] < element:\n",
    "      low = mid + 1\n",
    "    else:\n",
    "      high = mid\n",
    "  return False\n",
    "  \n",
    "def get_words(fname):\n",
    "    '''returns list of processed [no whitespace/capitalization] lines of text from given file'''\n",
    "    f = open(fname)\n",
    "    lines_original = f.readlines()\n",
    "    lines_processed = []\n",
    "    for line in lines_original:\n",
    "        lines_processed.append(line.strip().lower())\n",
    "    f.close()\n",
    "    lines_processed.sort()\n",
    "    return lines_processed\n",
    "\n",
    "def tokenize(message):\n",
    "    '''breaks message down into list of words without punctuation, whitespace, etc.'''\n",
    "    message = message.strip()\n",
    "    #print(message)\n",
    "    for num in string.digits:\n",
    "        message = message.replace(num, \"\")\n",
    "    for punc in string.punctuation:\n",
    "        if punc!=\"'\": # preserve contractions\n",
    "            message = message.replace(punc, \"\")\n",
    "    processed = message.split()\n",
    "    #print(processed)\n",
    "    stopwords = get_words(\"/Users/anisha/Downloads/sms-messages/stopwords.txt\")\n",
    "    #print(stopwords)\n",
    "    tokens = []\n",
    "    for token in processed:\n",
    "        if token!='' and not contains(stopwords, token.lower()):\n",
    "            tokens.append(token.lower())\n",
    "    #print(tokens)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "# main function for classifying messages\n",
    "def calculate_probability(message, isBusiness):\n",
    "    '''calculates probability all words of a given message are business/personal'''\n",
    "    global matrix\n",
    "    global allTokens \n",
    "    global businessTokens \n",
    "    global personalTokens\n",
    "    tokens = tokenize(message)\n",
    "    #print(tokens)\n",
    "    prob = 1\n",
    "    tokenCount = 0\n",
    "    if isBusiness:\n",
    "        categoryID = 0\n",
    "        category = businessTokens\n",
    "    else:\n",
    "        categoryID = 1\n",
    "        category = personalTokens\n",
    "    for token in tokens:\n",
    "        if token in category:\n",
    "            category_appearances = matrix[token][categoryID]\n",
    "        else:\n",
    "            category_appearances = 0\n",
    "        prob *= (category_appearances + 1)/(len(category) + len(allTokens))\n",
    "    return prob # average frequency of words\n",
    "\n",
    "# uses index to return True (for business) or False (for personal)\n",
    "def is_business(message):\n",
    "    '''classifies given message as business or personal'''\n",
    "    bus_prob = calculate_probability(message, True)\n",
    "    pers_prob = calculate_probability(message, False)\n",
    "    return bus_prob > pers_prob\n",
    "\n",
    "# main code to check messages\n",
    "\n",
    "fpath = \"/Users/anisha/Downloads/sms-messages/personal-biz.csv\"\n",
    "true_positive = 0\n",
    "false_positive = 0\n",
    "true_negative = 0\n",
    "false_negative = 0\n",
    "lines_read = 0\n",
    "matrix = {}\n",
    "allTokens = set()\n",
    "businessTokens = set()\n",
    "personalTokens = set()\n",
    "cutoff_num = 5000\n",
    "# go through set number of messages\n",
    "with open(fpath, newline='', encoding=\"latin1\") as messages_file:\n",
    "    lines = csv.DictReader(messages_file)\n",
    "    for line in lines:\n",
    "        lines_read += 1\n",
    "        answer = line['v1']\n",
    "        message = line['v2']\n",
    "        if lines_read < 4000:\n",
    "            # frequency train on first 4000\n",
    "            tokens = tokenize(message)\n",
    "            if answer==\"business\":\n",
    "                use = 0\n",
    "            else:\n",
    "                use = 1\n",
    "            for token in tokens:\n",
    "                if token not in allTokens:\n",
    "                    allTokens.add(token)\n",
    "                    matrix[token] = [0, 0]\n",
    "                matrix[token][use] += 1\n",
    "                if use==0 and token not in businessTokens:\n",
    "                    businessTokens.add(token)\n",
    "                elif use==1 and token not in personalTokens:\n",
    "                    personalTokens.add(token)\n",
    "        else:\n",
    "            # test on last 1000\n",
    "            sender = is_business(message)\n",
    "            #print(message, sender, answer)\n",
    "            # update counters for true/false positive/negatives\n",
    "            if sender==True:\n",
    "                if answer==\"business\":\n",
    "                    true_positive += 1\n",
    "                else:\n",
    "                    false_positive += 1\n",
    "            else:\n",
    "                if answer==\"personal\":\n",
    "                    true_negative += 1\n",
    "                else:\n",
    "                    false_negative += 1\n",
    "        if lines_read==cutoff_num:\n",
    "            break\n",
    "    # output results, calculate relevant measures\n",
    "    accuracy = (true_positive + true_negative)/(true_positive + false_positive + true_negative + false_negative)\n",
    "    precision = true_positive/(true_positive + false_positive)\n",
    "    recall = true_positive/(true_positive + false_negative)\n",
    "    print(\"{} true positives, {} false positives, {} true negatives, {} false negatives\".format(true_positive, false_positive, true_negative, false_negative))\n",
    "    print(\"accuracy {}, precision {}, recall {}\".format(accuracy, precision, recall))\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
